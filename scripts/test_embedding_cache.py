from __future__ import annotations

import shutil
import tempfile
from pathlib import Path

import numpy as np

# â”€â”€ Proje modÃ¼lÃ¼nÃ¼ import et â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from src.data.embedding_cache import (
    EmbeddingCacheDataset,
    EmbeddingCacheWriter,
    RADIOLOGICAL_DIM,
    TABULAR_DIM,
    cache_stats,
    is_cached,
)

# â”€â”€ Test ayarlarÄ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NUM_PATIENTS = 5
PATIENT_IDS = [10030053, 10037793, 10039757, 10082068, 10089641]
LABELS = [1, 1, 0, 0, 0]
# Hasta 0 â†’ 2 X-ray, diÄŸerleri â†’ 1 X-ray
NUM_XRAYS = [2, 1, 1, 1, 1]


def make_dummy_split_csv(splits_dir: Path) -> None:
    """GeÃ§ici split CSV oluÅŸturur (tÃ¼m hastalar train)."""
    splits_dir.mkdir(parents=True, exist_ok=True)
    csv_path = splits_dir / "fold_0_train.csv"
    with open(csv_path, "w") as f:
        f.write("patient_id,label\n")
        for pid, lbl in zip(PATIENT_IDS, LABELS):
            f.write(f"{pid},{lbl}\n")


def test_write(h5_path: Path) -> dict[str, np.ndarray]:
    """Dummy embedding'leri yazar. Orijinal array'leri dÃ¶ner."""
    rng = np.random.default_rng(42)
    originals: dict[str, np.ndarray] = {}

    with EmbeddingCacheWriter(h5_path) as writer:
        for i, pid in enumerate(PATIENT_IDS):
            # Tabular (fold=0 kullanÄ±yoruz)
            tab = rng.standard_normal(TABULAR_DIM).astype(np.float32)
            writer.save_tabular(pid, tab, fold=0)
            originals[f"tab_p{pid}"] = tab

            # Radiological (bazÄ± hastalarÄ±n birden fazla X-ray'i var)
            for j in range(NUM_XRAYS[i]):
                rad = rng.standard_normal(RADIOLOGICAL_DIM).astype(np.float32)
                # L2 normalize (RadJEPA gibi)
                rad = rad / np.linalg.norm(rad)
                writer.save_radiological(pid, rad, xray_idx=j)
                originals[f"rad_p{pid}_{j}"] = rad

        # Metadata
        writer.save_metadata(
            patient_ids=np.array(PATIENT_IDS, dtype=np.int64),
            labels=np.array(LABELS, dtype=np.int32),
            num_xrays=np.array(NUM_XRAYS, dtype=np.int32),
        )

    return originals


def test_read_and_verify(
    h5_path: Path,
    splits_dir: Path,
    originals: dict[str, np.ndarray],
) -> None:
    """Cache'ten okur ve orijinallerle karÅŸÄ±laÅŸtÄ±rÄ±r."""
    ds = EmbeddingCacheDataset(
        h5_path=h5_path,
        fold=0,
        split="train",
        splits_dir=splits_dir,
    )

    total_xrays = sum(NUM_XRAYS)
    assert len(ds) == total_xrays, (
        f"Beklenen sample sayÄ±sÄ± {total_xrays}, alÄ±nan {len(ds)}"
    )

    print(f"   Dataset repr: {ds!r}")
    print(f"   class_counts: {ds.class_counts}")
    print(f"   pos_weight: {ds.pos_weight:.2f}")

    # Her sample'Ä± doÄŸrula
    for idx in range(len(ds)):
        rad, tab, label = ds[idx]

        # Boyut kontrolÃ¼
        assert rad.shape == (RADIOLOGICAL_DIM,), f"Rad boyut hatasÄ± idx={idx}: {rad.shape}"
        assert tab.shape == (TABULAR_DIM,), f"Tab boyut hatasÄ± idx={idx}: {tab.shape}"

        # Tip kontrolÃ¼
        assert rad.dtype == torch.float32, f"Rad dtype hatasÄ±: {rad.dtype}"
        assert tab.dtype == torch.float32, f"Tab dtype hatasÄ±: {tab.dtype}"

    print("   âœ… TÃ¼m sample'lar doÄŸru boyut ve tipte")

    # Bitwise eÅŸitlik â€” ilk sample (patient 10030053, xray 0)
    rad_0, tab_0, lbl_0 = ds[0]
    orig_rad = originals["rad_p10030053_0"]
    orig_tab = originals["tab_p10030053"]

    assert np.array_equal(rad_0.numpy(), orig_rad), "Radiological bitwise eÅŸitlik BAÅARISIZ!"
    assert np.array_equal(tab_0.numpy(), orig_tab), "Tabular bitwise eÅŸitlik BAÅARISIZ!"
    assert lbl_0 == 1, f"Label hatasÄ±: beklenen 1, alÄ±nan {lbl_0}"

    print("   âœ… Bitwise eÅŸitlik doÄŸrulandÄ± (okuma == yazma)")


def test_helpers(h5_path: Path) -> None:
    """is_cached ve cache_stats helper fonksiyonlarÄ±nÄ± test eder."""
    # is_cached
    assert is_cached(h5_path, 10030053, "radiological"), "is_cached radiological BAÅARISIZ"
    assert is_cached(h5_path, 10030053, "tabular", fold=0), "is_cached tabular BAÅARISIZ"
    assert not is_cached(h5_path, 99999999, "radiological"), "is_cached false-positive!"

    print("   âœ… is_cached helper doÄŸru Ã§alÄ±ÅŸÄ±yor")

    # cache_stats
    stats = cache_stats(h5_path)
    assert stats["exists"] is True
    assert stats["num_radiological_embeddings"] == sum(NUM_XRAYS)
    assert stats["num_tabular_embeddings_total"] == NUM_PATIENTS
    assert stats["tabular_per_fold"]["fold_0"] == NUM_PATIENTS
    assert stats["num_unique_patients_radiological"] == NUM_PATIENTS

    print(f"   âœ… cache_stats: {stats['num_radiological_embeddings']} rad, "
          f"{stats['num_tabular_embeddings_total']} tab embeddings (fold_0={stats['tabular_per_fold']['fold_0']})")


def test_overwrite_protection(h5_path: Path) -> None:
    """force=False ile aynÄ± key tekrar yazÄ±ldÄ±ÄŸÄ±nda sessizce atlanÄ±r."""
    rng = np.random.default_rng(123)
    new_rad = rng.standard_normal(RADIOLOGICAL_DIM).astype(np.float32)
    new_tab = rng.standard_normal(TABULAR_DIM).astype(np.float32)

    with EmbeddingCacheWriter(h5_path) as writer:
        # force=False (default) â€” Ã¼zerine yazmaz
        writer.save_radiological(10030053, new_rad, xray_idx=0, force=False)
        writer.save_tabular(10030053, new_tab, fold=0, force=False)

    # Orijinal deÄŸer hÃ¢lÃ¢ korunmalÄ± (yeni deÄŸer yazÄ±lmamÄ±ÅŸ)
    import h5py
    with h5py.File(h5_path, "r") as f:
        stored_rad = f["radiological"]["p10030053_0"][:]
        assert not np.array_equal(stored_rad, new_rad), "force=False ama Ã¼zerine yazÄ±lmÄ±ÅŸ!"

    print("   âœ… Overwrite korumasÄ± Ã§alÄ±ÅŸÄ±yor (force=False)")


def main() -> None:
    print("=" * 60)
    print("  Embedding Cache (HDF5) Smoke Test")
    print("=" * 60 + "\n")

    tmpdir = Path(tempfile.mkdtemp(prefix="test_embedding_cache_"))
    h5_path = tmpdir / "test_embeddings.h5"
    splits_dir = tmpdir / "splits"

    try:
        # 1) Dummy split oluÅŸtur
        print("1ï¸âƒ£  Dummy split CSV oluÅŸturuluyor...")
        make_dummy_split_csv(splits_dir)
        print(f"   â†’ {splits_dir}/fold_0_train.csv\n")

        # 2) Yazma testi
        print("2ï¸âƒ£  Embedding'ler yazÄ±lÄ±yor...")
        originals = test_write(h5_path)
        print(f"   â†’ {h5_path} ({h5_path.stat().st_size / 1024:.1f} KB)\n")

        # 3) Okuma ve doÄŸrulama
        print("3ï¸âƒ£  Okuma ve doÄŸrulama...")
        test_read_and_verify(h5_path, splits_dir, originals)
        print()

        # 4) Helper fonksiyonlar
        print("4ï¸âƒ£  Helper fonksiyonlar...")
        test_helpers(h5_path)
        print()

        # 5) Overwrite korumasÄ±
        print("5ï¸âƒ£  Overwrite korumasÄ±...")
        test_overwrite_protection(h5_path)
        print()

        print("=" * 60)
        print("  ğŸ‰ TÃ¼m testler baÅŸarÄ±lÄ±!")
        print("=" * 60)

    finally:
        # Temizlik
        shutil.rmtree(tmpdir, ignore_errors=True)
        print(f"\nğŸ§¹ GeÃ§ici dizin temizlendi: {tmpdir}")


if __name__ == "__main__":
    import torch  # noqa: E402 â€” test_read_and_verify'de lazÄ±m

    main()
