# ğŸ¥ Multimodal Mortalite Tahmini Pipeline'Ä±

> **Proje**: CDSL GÃ¶ÄŸÃ¼s RÃ¶ntgeni + Tabular Veri ile **Binary Mortalite SÄ±nÄ±flandÄ±rma (Death vs Survived)**  
> **Mimari**: Frozen RadJEPA (GÃ¶rÃ¼ntÃ¼) + Frozen TabPFN v2 (Tabular) â†’ Projection Head â†’ Binary Classifier  
> **Hedef**: Deterministik, reprodÃ¼se edilebilir, klinik gÃ¼venilirlikte bir mortalite tahmin sistemi

---

## Ä°Ã§indekiler

1. [FAZ 0 â€” Pre-Flight Check](#faz-0--pre-flight-check)
2. [FAZ 1 â€” Veri AltyapÄ±sÄ± ve Determinizm](#faz-1--veri-altyapÄ±sÄ±-ve-determinizm)
3. [FAZ 2 â€” Frozen Embedding Ã‡Ä±karÄ±mÄ±](#faz-2--frozen-embedding-Ã§Ä±karÄ±mÄ±)
4. [FAZ 3 â€” Boyut Ä°ndirgeme ve Fusion Mimarisi](#faz-3--boyut-indirgeme-ve-fusion-mimarisi)
5. [FAZ 4 â€” Binary EÄŸitim ProtokolÃ¼](#faz-4--binary-eÄŸitim-protokolÃ¼)
6. [FAZ 5 â€” RobustlaÅŸtÄ±rma ve Augmentasyon](#faz-5--robustlaÅŸtÄ±rma-ve-augmentasyon)
7. [FAZ 6 â€” Kalibrasyon ve Klinik Validasyon](#faz-6--kalibrasyon-ve-klinik-validasyon)
8. [FAZ 7 â€” ReprodÃ¼ksiyon ve Paketleme](#faz-7--reprodÃ¼ksiyon-ve-paketleme)
9. [Sorun-Ã‡Ã¶zÃ¼m Tablosu](#sorun-Ã§Ã¶zÃ¼m-tablosu)

---

## FAZ 0 â€” Pre-Flight Check

### 0.1 Exploratory Data Analysis (EDA)

Veri setine dokunmadan Ã¶nce sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± analiz et.

**Binary SÄ±nÄ±flandÄ±rma (Death vs Survived):**

| SÄ±nÄ±f | Label | Kaynak SÃ¼tun | AÃ§Ä±klama |
|-------|-------|-------------|----------|
| Death | 1 | `destin_discharge == "Death"` | Hastanede Ã¶len hastalar (550) |
| Survived | 0 | `destin_discharge != "Death"` | Taburcu olan hastalar (3,929) |

> [!NOTE]
> **Karar:** Tek aÅŸamalÄ± binary classification: mortalite tahmini. `destin_discharge` sÃ¼tunundaki "Death" deÄŸeri pozitif sÄ±nÄ±f olarak kullanÄ±lÄ±r. DiÄŸer tÃ¼m taburculuk durumlarÄ± (Home, Transfer, Voluntary Discharge, vb.) "Survived" olarak etiketlenir.

**Eksik Veri Analizi:**
- `glu_first_emerg` (%99 NaN) â†’ silindi
- Temiz veri: 4,479 satÄ±r Ã— 17 sÃ¼tun (`tabpfn_features_clean.csv`)
- OranlarÄ± not et â†’ %20+ eksik varsa **modality dropout** daha kritik hale gelir.

### 0.2 DonanÄ±m ve Ortam KontrolÃ¼

| Kontrol | Komut / YÃ¶ntem | Beklenen |
|---------|----------------|----------|
| MPS kullanÄ±labilirliÄŸi | `torch.backends.mps.is_available()` | `True` (M2) |
| Disk alanÄ± | LMDB cache iÃ§in | ~50GB boÅŸ alan |
| RAM | RadJEPA Ã§Ä±karÄ±mÄ± | 16GB+ (swap kontrol et) |

> [!WARNING]
> MPS backend'i deterministik deÄŸildir. CPU fallback planÄ± hazÄ±r tutulmalÄ±.

---

## FAZ 1 â€” Veri AltyapÄ±sÄ± ve Determinizm

### 1.1 Deterministik Seed AltyapÄ±sÄ±

TÃ¼m kÃ¼tÃ¼phane seed'leri merkezi config dosyasÄ±nda saklanÄ±r:

```yaml
# config/config.yaml
seed: 42
cv:
  n_folds: 10
```

**Ek Ayarlar:**
- `PIL.ImageFile.LOAD_TRUNCATED_IMAGES = False` â€” truncasyon kaynaklÄ± non-determinizm engellenir
- `torch.set_num_threads(1)` + `OMP_NUM_THREADS=1` â€” multi-threading kaynaklÄ± non-determinizm engellenir

### 1.2 Stratified 10-Fold Split

> [!IMPORTANT]
> AynÄ± hastanÄ±n farklÄ± zamanlardaki gÃ¶rÃ¼ntÃ¼leri **aynÄ± fold'da** olmalÄ±dÄ±r. Aksi halde data leakage oluÅŸur.

**AdÄ±mlar:**
1. Patient ID'leri unique olarak al
2. `StratifiedKFold(n_splits=10)` uygula (patient-level, mortalite label'Ä±na gÃ¶re strateji)
3. Her fold'da minimum sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± kontrol et
4. Split dosyalarÄ±nÄ± kaydet: `fold_{0-9}_train.csv`, `fold_{0-9}_val.csv`

> [!CAUTION]
> Asla kod iÃ§inde dinamik split yapma. KayÄ±tlÄ± split dosyalarÄ± **source of truth** olmalÄ±dÄ±r.

### 1.3 LMDB Cache Sistemi

**AmaÃ§:** Her epoch'ta yapÄ±lan PIL/OpenCV resize iÅŸlemlerinin yavaÅŸlÄ±ÄŸÄ±nÄ± ve non-determinizmini Ã¶nleme.

**Hash Fonksiyonu:**
```
hash = SHA256(image_path + str(resize_size) + str(normalization_params))
```

**LMDB OluÅŸturma:**
1. Her gÃ¶rÃ¼ntÃ¼yÃ¼ 224Ã—224 olarak resize et (LANCZOS veya BILINEAR â€” **sabit bir interpolasyon** seÃ§)
2. Tensor â†’ numpy array â†’ compress (blosc/lz4)
3. Key: hash, Value: compressed array

**Validasyon:**
```python
assert torch.equal(tensor_run1, tensor_run2)  # Bitwise eÅŸitlik ÅŸart
```

> [!TIP]
> LMDB toplam boyutu kontrol et. Ã‡ok kÃ¼Ã§Ã¼kse (Ã¶r. 2GB) fazla compression veya eksik kayÄ±t olabilir.

---

## FAZ 2 â€” Frozen Embedding Ã‡Ä±karÄ±mÄ±

> [!NOTE]
> Embedding Ã§Ä±karÄ±mÄ± **train'den Ã–NCE** bir kez yapÄ±lÄ±r ve HDF5'e cache'lenir. EÄŸitim sÄ±rasÄ±nda tekrar Ã§Ä±karÄ±m yok.
>
> **Ã‡alÄ±ÅŸtÄ±rma SÄ±rasÄ±:**
> ```bash
> # 1) TabPFN (per-fold, ~10 ayrÄ± model fit)
> PYTHONPATH=. uv run python scripts/extract_tabpfn_embeddings.py
>
> # 2) RadJEPA (tÃ¼m veri, tek seferlik)
> PYTHONPATH=. uv run python scripts/extract_radjepa_embeddings.py
> ```

### 2.1 TabPFN v2 Entegrasyonu (Tabular â†’ 192-dim)

| Parametre | DeÄŸer |
|-----------|-------|
| Ã‡Ä±ktÄ± boyutu | 192-dim |
| Eksik deÄŸerler | `np.nan` (dummy deÄŸer koyma!) |
| Feature sÄ±rasÄ± | `feature_columns.txt`'ye kaydet |
| Checkpoint | Her 100 hastada `.npy`'ye kaydet |

**Kritik:** TabPFN'in `predict` deÄŸil `embed` fonksiyonunu kullan.

> [!CAUTION]
> **Hybrid Per-Fold Cache (Data Leakage Ã–nlemi):**
> TabPFN, RadJEPAâ€™dan farklÄ± olarak **label bilgisini gÃ¶rerek** embedding Ã¼retir.
> TÃ¼m veriyi tek seferde TabPFNâ€™e verip sonra foldâ€™lara bÃ¶lmek **data leakage** oluÅŸturur.
>
> **Ã‡Ã¶zÃ¼m:** Her fold `k` iÃ§in ayrÄ± bir TabPFN modeli sadece fold `k`â€™nÄ±n **train** setindeki
> verilerle eÄŸitilir, sonra fold `k`â€™nÄ±n **val** setindeki hastalara embedding Ã¼retir.
> BÃ¶ylece hiÃ§bir validasyon hastasÄ±nÄ±n labelâ€™Ä±, kendi embeddingâ€™ini Ã¼reten modele sÄ±zmaz.
>
> **HDF5 YapÄ±sÄ±:** `tabular/fold_{k}/p{pid}` (RadJEPA fold-agnostic kalÄ±r)

### 2.2 RadJEPA Entegrasyonu (GÃ¶rÃ¼ntÃ¼ â†’ 768-dim)

**MPS vs CPU KararÄ±:**

| SeÃ§enek | HÄ±z | Determinizm | Not |
|---------|-----|-------------|-----|
| CPU | ğŸ¢ YavaÅŸ | âœ… Garantili | GÃ¼venli seÃ§enek |
| MPS | ğŸš€ HÄ±zlÄ± | âš ï¸ Kontrol gerekli | `torch.inference_mode()` + 3-5 Ã¶rnekle CPU karÅŸÄ±laÅŸtÄ±rmasÄ± yap |

**Post-Processing (Zorunlu):**
```python
embedding = embedding / np.linalg.norm(embedding)  # L2 Normalize
```

> [!IMPORTANT]
> RadJEPA contrastive pretraining ile eÄŸitilmiÅŸ, cosine space'de Ã§alÄ±ÅŸÄ±r. L2 normalizasyonu atlanmamalÄ±dÄ±r.

**Augmentasyon:** RadJEPA frozen olduÄŸu iÃ§in **augmentasyon YAPILMAZ**.

**Cache YapÄ±sÄ±:**
```
embeddings.h5
â”œâ”€â”€ radiological/
â”‚   â”œâ”€â”€ p10030053_0    # fold-agnostic (RadJEPA label gÃ¶rmez)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ tabular/
â”‚   â”œâ”€â”€ fold_0/
â”‚   â”‚   â”œâ”€â”€ p10394712  # Fold 0 val hastasÄ±, Fold 0 train ile eÄŸitilmiÅŸ model
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ fold_1/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ fold_{n}/
â””â”€â”€ metadata/
```

**Kontrol:** Embedding boyutlarÄ±nÄ± doÄŸrula (192 ve 768). `nan`/`inf` varsa â†’ batch size=1'e dÃ¼ÅŸÃ¼r.

---

## FAZ 3 â€” Boyut Ä°ndirgeme ve Fusion Mimarisi

### 3.1 Projection Head TasarÄ±mÄ±

**Parametre BÃ¼tÃ§esi:** N=2,500 Ã¶rnek â†’ max ~250k trainable parametre (N/10 kuralÄ±).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tabular Path   â”‚     â”‚   Vision Path    â”‚
â”‚  192 â†’ 64       â”‚     â”‚   768 â†’ 128      â”‚
â”‚  LayerNorm(64)  â”‚     â”‚   LayerNorm(128) â”‚
â”‚  GELU           â”‚     â”‚   GELU           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ Concat
           â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
           â”‚  192-dim   â”‚
           â”‚ Joint Spaceâ”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> [!NOTE]
> **BatchNorm deÄŸil, LayerNorm** kullan â€” kÃ¼Ã§Ã¼k batch size'da BatchNorm instabil olur.

**Kontrol:** Toplam trainable parametre ~30-40k civarÄ± olmalÄ±. 500k+ â†’ overfit riski (boyutlarÄ± kÃ¼Ã§Ã¼lt).

### 3.2 Modality Dropout

Her batch'te rastgele bir deÄŸer Ã¼ret (0-1):

| AralÄ±k | DavranÄ±ÅŸ |
|--------|----------|
| `< 0.1` | Tabular = 0 vektÃ¶rÃ¼, sadece gÃ¶rÃ¼ntÃ¼ |
| `0.1 - 0.2` | GÃ¶rÃ¼ntÃ¼ = 0 vektÃ¶rÃ¼, sadece tabular |
| `> 0.2` | Her iki modalite de kullanÄ±lÄ±r |

> [!IMPORTANT]
> `torch.zeros_like(input)` kullan, mean imputation **YAPMA**. LayerNorm sonrasÄ± 0 vektÃ¶rÃ¼ belirli bir pattern oluÅŸturur ve model "bu modalite eksik" sinyalini Ã¶ÄŸrenir.

---

## FAZ 4 â€” Binary EÄŸitim ProtokolÃ¼

### 4.1 Tek AÅŸamalÄ± Binary Training (Death vs Survived)

| Parametre | DeÄŸer |
|-----------|-------|
| Label | Survived=0, Death=1 |
| Loss | `BCEWithLogitsLoss` (pos_weight ile class dengeleme) |
| Optimizer | AdamW (weight_decay=1e-4) |
| LR | 1e-3 |
| Early stopping | Val loss 10 epoch dÃ¼ÅŸmezse dur |
| Cross-validation | 10-fold (patient-level StratifiedKFold) |

**Class Weight:** Inverse frequency hesapla:
```python
pos_weight = n_survived / n_death  # â‰ˆ 7.14 (3,929 / 550)
```

**Kontrol:** Val AUROC > 0.80 ve Sensitivity@Specificity=0.95 takip edilmeli. Mortalite sÄ±nÄ±f dengesizliÄŸi yÃ¼ksek (~7:1), Focal Loss alternatif olarak dÃ¼ÅŸÃ¼nÃ¼lebilir.

### 4.2 Inference Logic

```
Input: Hasta embedding'i (192-dim fused)

Model â†’ logit â†’ sigmoid â†’ prob_death
  â”œâ”€â”€ prob_death > 0.5 â†’ "Death"      (confidence = prob_death)
  â””â”€â”€ prob_death â‰¤ 0.5 â†’ "Survived"   (confidence = 1 - prob_death)
```

**GÃ¼ven Skoru:** Sigmoid Ã§Ä±ktÄ±sÄ± direkt confidence olarak kullanÄ±lÄ±r. Kalibrasyon sonrasÄ± Temperature Scaling ile dÃ¼zeltilir.

---

## FAZ 5 â€” RobustlaÅŸtÄ±rma ve Augmentasyon

### 5.1 Embedding Space Mixup

```python
lam = np.random.beta(0.2, 0.2)  # UÃ§ deÄŸerler daha olasÄ± (%90-%10 karÄ±ÅŸÄ±mlar)
mixed_emb   = lam * emb_i + (1 - lam) * emb_j
mixed_label = lam * label_i + (1 - lam) * label_j  # Soft label
```

> [!NOTE]
> Embedding space'te mixup yapÄ±lÄ±r Ã§Ã¼nkÃ¼ RadJEPA/TabPFN embedding'leri smooth manifold Ã¼zerindedir. Ham gÃ¶rÃ¼ntÃ¼de mixup anlamsÄ±z sonuÃ§lar Ã¼retir.

### 5.2 Gaussian Noise Regularization

```python
noise = 0.05 * batch_std * torch.randn_like(embedding)
augmented_embedding = embedding + noise
```

### 5.3 Agresif Dropout

| Alan | Dropout OranÄ± | Not |
|------|---------------|-----|
| Joint space (classification Ã¶ncesi) | `p=0.6` | 2.5k veri iÃ§in gerekli |
| Underfit durumunda | `p=0.4`'e dÃ¼ÅŸÃ¼r | Train loss dÃ¼ÅŸmÃ¼yorsa |

---

## FAZ 6 â€” Kalibrasyon ve Klinik Validasyon

### 6.1 Temperature Scaling (Her Fold Ä°Ã§in AyrÄ±)

- Grid search: T = 0.5 â†’ 3.0 (50 adÄ±m)
- Her T iÃ§in ECE (Expected Calibration Error) hesapla
- En dÃ¼ÅŸÃ¼k ECE â†’ seÃ§ilen T

**Tek T deÄŸeri** (binary classifier iÃ§in).

### 6.2 Uncertainty Thresholding (Reject Option)

| Confidence | Ã‡Ä±ktÄ± |
|------------|-------|
| â‰¥ 0.7 | Model tahmini kabul edilir |
| < 0.7 | "Belirsiz â€” Radyolog Ä°ncelemesi Gerekli" |

**Hedef:** %10-15 reject oranÄ±, kalan Ã¶rneklerde %95+ accuracy.

### 6.3 Metrik Hesaplama

| Metrik | AÃ§Ä±klama |
|--------|----------|
| **AUROC** | Binary classifier iÃ§in birincil metrik |
| **F1-Score** | Precision/Recall dengesi |
| **Sensitivity@Spec=0.95** | Mortalite iÃ§in spec=0.95 sabitken max sensitivity |
| **Calibration Curve** | Reliability diagram (predicted conf vs actual acc) |
| **Modality Ablation** | Sadece tabular / sadece gÃ¶rÃ¼ntÃ¼ / ikisi birlikte |

---

## FAZ 7 â€” ReprodÃ¼ksiyon ve Paketleme

### 7.1 Determinizm DoÄŸrulama
- TÃ¼m pipeline'Ä± cache'siz tekrar Ã§alÄ±ÅŸtÄ±r
- Ä°lk vs ikinci Ã§alÄ±ÅŸtÄ±rma metrikleri **bitwise aynÄ±** olmalÄ± (float32)
- DeÄŸilse â†’ non-deterministik katman var (Dropout seed'lenmemiÅŸ, BatchNorm kullanÄ±lmÄ±ÅŸ vb.)

### 7.2 Embedding Cache Checksum
- TÃ¼m `.npy` dosyalarÄ±nÄ±n SHA256 hash'leri â†’ `manifest.json`
- FarklÄ± makinede hash doÄŸrulamasÄ±

### 7.3 Requirements Freeze
```bash
pip freeze > requirements.txt
```
- CUDA/MPS versiyonlarÄ±nÄ± not et

### 7.4 DokÃ¼mantasyon Ã‡Ä±ktÄ±larÄ±

| Dosya | Ä°Ã§erik |
|-------|--------|
| `fold_assignments.csv` | Hangi hasta hangi fold'da |
| `temperature_values.json` | Her fold iÃ§in T deÄŸeri |
| `strategy_rationale.md` | Binary classification seÃ§im nedeni |
| `reject_report.json` | "Belirsiz" olarak reddedilen Ã¶rnekler |

---

## Sorun-Ã‡Ã¶zÃ¼m Tablosu

| Durum | TanÄ± | Ã‡Ã¶zÃ¼m |
|-------|------|-------|
| Val loss > train loss (sabit) | Overfitting | Dropout â†’ 0.6, PCA (768â†’64), Mixup aÃ§, epoch 50â†’20 |
| Sadece Survived tahmini (Death hiÃ§ tahmin edilmiyor) | Åiddetli Class Imbalance (~7:1) | `pos_weightâ‰ˆ7.14` ayarla, focal loss dene, oversampling |
| Modality Collapse | Tabular ignore ediliyor | Modality dropout â†’ p=0.3, tabular projection 64â†’128 |
| ECE > 0.2 | KÃ¶tÃ¼ kalibrasyon | Grid search 0.1-5.0, Platt Scaling dene |
| MPS OOM | Memory yetmezliÄŸi | Batch size=1, RadJEPA CPU'da, gradient checkpointing |
| AynÄ± hasta train+val'de | Data Leakage | `GroupKFold` + patient_id bazlÄ± split |
